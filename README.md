# ğŸ§  Clasificador AutomÃ¡tico de ArtÃ­culos BiomÃ©dicos

Este proyecto desarrolla un **clasificador automÃ¡tico de artÃ­culos biomÃ©dicos** ğŸ©º a partir de su tÃ­tulo y resumen (abstract). La soluciÃ³n asigna los textos a uno de los siguientes dominios mÃ©dicos:

- â¤ï¸ Cardiovascular
- ğŸ§  Neurological
- ğŸ§¬ Oncological
- ğŸ©¸ Hepatorenal

La soluciÃ³n se basa en **Machine Learning supervisado** ğŸ¤–. El pipeline de procesamiento de texto utiliza TF-IDF para la vectorizaciÃ³n y un **Support Vector Machine (SVM)** como modelo de clasificaciÃ³n. El SVM fue elegido por su robustez, su capacidad para manejar datos de alta dimensionalidad y las opciones de regularizaciÃ³n para mejorar el rendimiento en escenarios con clases desbalanceadas.

---

## ğŸš€ Acceso al Proyecto

Puedes interactuar con el modelo y ver los resultados de dos maneras:

### ğŸŒ AplicaciÃ³n Web
Accede a la aplicaciÃ³n web desplegada, donde puedes probar el clasificador sin necesidad de instalaciones.
**Nota: Recuerda leer el manual de uso que se encuentra al final del documento antes de comenzar tu experiencia en la plataforma.**
[Ir a la aplicaciÃ³n web â¤ï¸](https://v0-medical-text-classifier.vercel.app/)
â˜ï¸ Ten en cuenta que el modelo puede tardar varios minutos en procesar, dependiendo del tamaÃ±o del conjunto de datos de prueba ğŸ˜Š.

### ğŸ’» Notebook de Colab
Explora el proceso de desarrollo completo, desde el anÃ¡lisis exploratorio de datos hasta la evaluaciÃ³n del modelo en el siguiente notebook de Google Colab.
[Ver notebook en Google Colab](https://colab.research.google.com/drive/1gSH9f-nLw-whV7MiXg5xBT74eqq1TD4B?usp=sharing)
**Se recomienda siempre abrir y visualizar este notebook en Jupyter Notebook o Google Colab**.

---

## ğŸ› ï¸ Estructura del Repositorio y Uso

La organizaciÃ³n del proyecto sigue una **estructura modular** para mejorar la claridad y la **reutilizaciÃ³n del cÃ³digo** â™»ï¸. El cÃ³digo estÃ¡ escrito y formateado segÃºn la guÃ­a **PEP 8** para garantizar su legibilidad.

### Diagrama de la SoluciÃ³n

![Diagrama de Flujo de la SoluciÃ³n](Flujo_Trabajo/Flujo_Trabajo.jpeg)

El diagrama explica el diseÃ±o de la soluciÃ³n, desde la ingesta de datos hasta la predicciÃ³n, mostrando cÃ³mo las diferentes partes del proyecto se conectan entre sÃ­.

### Estructura del Proyecto

```
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ ğŸ“„ Challenge_de_ClasificaciÃ³n_BiomÃ©dica_IA.ipynb  \# Notebook con EDA y entrenamiento del modelo.
â”œâ”€â”€ Flujo de Trabajo/
â”‚   â”œâ”€â”€ ğŸ“„ Flujo de Trabajo.jpg
â”œâ”€â”€ model/
â”‚   â””â”€â”€ ğŸ“„ Clasification_model.pkl  \# Modelo de clasificaciÃ³n.
â”œâ”€â”€ test/
â”‚   â””â”€â”€ ğŸ“„ Data1.csv \# Data para pruebas.
â”‚   â””â”€â”€ ğŸ“„ Data2.csv \# Data para pruebas.
â”‚   â””â”€â”€ ğŸ“„ Data3.csv \# Data para pruebas.
â”‚   â””â”€â”€ ğŸ“„ Data4.csv \# Data para pruebas.
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ requirements.txt  \# Lista de dependencias.
```
**Nota sobre los CSV de prueba**:

- En la carpeta `test/` se encuentran **4 CSV de ejemplo** que pueden usarse para probar el notebook.
- Si quieres ejecutar el notebook, Recuerda que, inmediatamente despuÃ©s de importar las librerÃ­as, debes modificar la ruta (path) segÃºn el csv de prueba que quieras usar.
- En caso de que quieras probar un **CSV personalizado** en la aplicaciÃ³n web:
  - Debe tener las columnas `title;abstract;group` (el `group` es opcional para validaciÃ³n).
  - El archivo **no debe superar las 1000 filas**, debido a que el modelo se carga en la versiÃ³n gratuita de Hugging Face. Para eliminar esta limitaciÃ³n, serÃ­a necesario utilizar la **versiÃ³n premium** de Hugging Face.
- Si pruebas desde el **notebook**, no hay lÃ­mite en la cantidad de filas.

---

### ğŸ“¦ Dependencias e InstalaciÃ³n
Para ejecutar el cÃ³digo localmente (si decides migrar del notebook a archivos `.py`), necesitas Python 3.8+ y las bibliotecas listadas en `requirements.txt`.

1.  Clona el repositorio:
    ```bash
    git clone [https://github.com/tu_usuario/nombre_del_repo.git](https://github.com/tu_usuario/nombre_del_repo.git)
    cd nombre_del_repo
    ```
2.  Instala las dependencias:
    ```bash
    pip install -r requirements.txt
    ```

---

## ğŸ“‹ Manual de Uso

Este manual se centra en el uso de la aplicaciÃ³n web, que es la interfaz principal para los usuarios finales.

### 1. Carga de CSV
- Sube un archivo CSV con las columnas: `title`, `abstract` y, opcionalmente, `group` (para validaciÃ³n).
- El formato del archivo debe ser `title;abstract;group`.
- Haz clic en **"Procesar Predicciones"** para clasificar automÃ¡ticamente todos los textos.

### 2. PredicciÃ³n Manual
- Ingresa el **tÃ­tulo** y el **resumen** del texto biomÃ©dico que deseas clasificar.
- Haz clic en **"Clasificar Texto"** para obtener la predicciÃ³n instantÃ¡nea.
- Los resultados incluyen la **categorÃ­a predicha** y el **nivel de confianza**.

### 3. CategorÃ­as de ClasificaciÃ³n
El sistema clasifica los textos en las siguientes categorÃ­as:

- **Neurological**: Textos sobre neurologÃ­a y el sistema nervioso.
- **Cardiovascular**: Textos sobre cardiologÃ­a y el sistema cardiovascular.
- **Oncological**: Textos sobre oncologÃ­a y cÃ¡ncer.
- **Hepatorenal**: Textos sobre hÃ­gado y riÃ±ones.

### 4. Dashboard de Resultados
- Visualiza estadÃ­sticas clave como la **precisiÃ³n** y la **distribuciÃ³n de categorÃ­as**.
- Visualiza mÃ©tricas como F1-score ponderado, accuracy, distribuciÃ³n de clases y la matriz de confusiÃ³n. Para acceder a esta informaciÃ³n, haz clic en el botÃ³n **MÃ©tricas Extendidas**.
- **Filtra los resultados** por categorÃ­a o por el origen de la predicciÃ³n (CSV vs. Manual).
- **Exporta** los resultados en formato CSV para anÃ¡lisis posterior.

---

ğŸ’¡ **Consejos**
- Para obtener mejores resultados, asegÃºrate de que los textos estÃ©n en **inglÃ©s**.
- Los **tÃ­tulos y resÃºmenes mÃ¡s descriptivos** tienden a generar clasificaciones mÃ¡s precisas.
````
